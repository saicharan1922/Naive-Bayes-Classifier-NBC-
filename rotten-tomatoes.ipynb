{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Freshness</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fresh</td>\n",
       "      <td>Manakamana doesn't answer any questions, yet ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fresh</td>\n",
       "      <td>Wilfully offensive and powered by a chest-thu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rotten</td>\n",
       "      <td>It would be difficult to imagine material mor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rotten</td>\n",
       "      <td>Despite the gusto its star brings to the role...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rotten</td>\n",
       "      <td>If there was a good idea at the core of this ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Freshness                                             Review\n",
       "0     fresh   Manakamana doesn't answer any questions, yet ...\n",
       "1     fresh   Wilfully offensive and powered by a chest-thu...\n",
       "2    rotten   It would be difficult to imagine material mor...\n",
       "3    rotten   Despite the gusto its star brings to the role...\n",
       "4    rotten   If there was a good idea at the core of this ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"rt_reviews.csv\"\n",
    "df = pd.read_csv(\"rt_reviews.csv\", encoding='ISO-8859-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.sample(96000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shuffled = df.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the sizes of the train, deve, and test\n",
    "# Keeping 80% for training\n",
    "# 10% for dev\n",
    "# 10# for testing\n",
    "train_size = int(0.8 * len(df))\n",
    "dev_size = int(0.1 * len(df))\n",
    "test_size = len(df) - train_size - dev_size\n",
    "\n",
    "# Splitting the datasets\n",
    "train_df = df_shuffled[:train_size]\n",
    "dev_df = df_shuffled[train_size : train_size + dev_size]\n",
    "test_df = df_shuffled[train_size + dev_size :]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = Counter()\n",
    "for review in train_df['Review']:\n",
    "    tokens = review.lower().split()\n",
    "    word_counts.update(tokens)\n",
    "\n",
    "# Building vocabulary and reverse indices\n",
    "min_occurrences = 5\n",
    "vocabulary = [word for word, count in word_counts.items() if count >= min_occurrences]\n",
    "reverse_index = {word: idx for idx, word in enumerate(vocabulary)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(the) = 0.6342083333333334\n",
      "P(the|fresh) = 0.6352426992279883\n",
      "P(the|rotten) = 0.6331743337117386\n"
     ]
    }
   ],
   "source": [
    "# Tokenizing and creating counters\n",
    "word_counts = Counter()\n",
    "sentiment_word_counts = {'fresh': Counter(), 'rotten': Counter()}\n",
    "\n",
    "for _, row in train_df.iterrows():\n",
    "    sentiment, review = row['Freshness'], row['Review']\n",
    "    tokens = set(review.lower().split())\n",
    "    word_counts.update(tokens)\n",
    "    sentiment_word_counts[sentiment].update(tokens)\n",
    "\n",
    "# Calculating the probabilities\n",
    "num_documents = len(train_df)\n",
    "num_fresh_documents = sum(train_df['Freshness'] == 'fresh')\n",
    "num_rotten_documents = sum(train_df['Freshness'] == 'rotten')\n",
    "\n",
    "p_the = word_counts['the'] / num_documents\n",
    "p_the_given_fresh = sentiment_word_counts['fresh']['the'] / num_fresh_documents\n",
    "p_the_given_rotten = sentiment_word_counts['rotten']['the'] / num_rotten_documents\n",
    "\n",
    "print(f\"P(the) = {p_the}\")\n",
    "print(f\"P(the|fresh) = {p_the_given_fresh}\")\n",
    "print(f\"P(the|rotten) = {p_the_given_rotten}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_conditional_probabilities(vocabulary, sentiment_word_counts, num_fresh_documents, num_rotten_documents, smoothing=1):\n",
    "    fresh_probs = {}\n",
    "    rotten_probs = {}\n",
    "    vocab_size = len(vocabulary)\n",
    "    \n",
    "    for word in vocabulary:\n",
    "        fresh_count = sentiment_word_counts['fresh'][word]\n",
    "        rotten_count = sentiment_word_counts['rotten'][word]\n",
    "        \n",
    "        fresh_prob = (fresh_count + smoothing) / (num_fresh_documents + vocab_size * smoothing)\n",
    "        rotten_prob = (rotten_count + smoothing) / (num_rotten_documents + vocab_size * smoothing)\n",
    "        \n",
    "        fresh_probs[word] = fresh_prob\n",
    "        rotten_probs[word] = rotten_prob\n",
    "    \n",
    "    return fresh_probs, rotten_probs\n",
    "\n",
    "def naive_bayes_classifier(review, vocabulary, fresh_probs, rotten_probs):\n",
    "    tokens = set(review.lower().split())\n",
    "    tokens = [token for token in tokens if token in vocabulary]\n",
    "    \n",
    "    fresh_prob = np.prod([fresh_probs[token] for token in tokens])\n",
    "    rotten_prob = np.prod([rotten_probs[token] for token in tokens])\n",
    "\n",
    "    return 'fresh' if fresh_prob > rotten_prob else 'rotten'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8030208333333333\n"
     ]
    }
   ],
   "source": [
    "# Calculating the conditional probabilities\n",
    "fresh_probs, rotten_probs = calculate_conditional_probabilities(vocabulary, sentiment_word_counts, num_fresh_documents, num_rotten_documents, smoothing=0)\n",
    "\n",
    "# Classifing reviews in the development dataset and calculate accuracy\n",
    "correct_predictions = 0\n",
    "for _, row in dev_df.iterrows():\n",
    "    sentiment, review = row['Freshness'], row['Review']\n",
    "    predicted_sentiment = naive_bayes_classifier(review, vocabulary, fresh_probs, rotten_probs)\n",
    "    if predicted_sentiment == sentiment:\n",
    "        correct_predictions += 1\n",
    "\n",
    "accuracy = correct_predictions / len(dev_df)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Laplace smoothing: 0.8052291666666667\n",
      "Accuracy without smoothing: 0.8030208333333333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Calculate the conditional probabilities with and without Laplace smoothing\n",
    "fresh_probs_smoothed, rotten_probs_smoothed = calculate_conditional_probabilities(vocabulary, sentiment_word_counts, num_fresh_documents, num_rotten_documents, smoothing=1)\n",
    "fresh_probs_unsmoothed, rotten_probs_unsmoothed = calculate_conditional_probabilities(vocabulary, sentiment_word_counts, num_fresh_documents, num_rotten_documents, smoothing=0)\n",
    "\n",
    "# Classify reviews in the development dataset and calculate accuracy for both cases\n",
    "correct_predictions_smoothed = 0\n",
    "correct_predictions_unsmoothed = 0\n",
    "\n",
    "for _, row in dev_df.iterrows():\n",
    "    sentiment, review = row['Freshness'], row['Review']\n",
    "    \n",
    "    predicted_sentiment_smoothed = naive_bayes_classifier(review, vocabulary, fresh_probs_smoothed, rotten_probs_smoothed)\n",
    "    if predicted_sentiment_smoothed == sentiment:\n",
    "        correct_predictions_smoothed += 1\n",
    "\n",
    "    predicted_sentiment_unsmoothed = naive_bayes_classifier(review, vocabulary, fresh_probs_unsmoothed, rotten_probs_unsmoothed)\n",
    "    if predicted_sentiment_unsmoothed == sentiment:\n",
    "        correct_predictions_unsmoothed += 1\n",
    "\n",
    "accuracy_smoothed = correct_predictions_smoothed / len(dev_df)\n",
    "accuracy_unsmoothed = correct_predictions_unsmoothed / len(dev_df)\n",
    "\n",
    "print(f\"Accuracy with Laplace smoothing: {accuracy_smoothed}\")\n",
    "print(f\"Accuracy without smoothing: {accuracy_unsmoothed}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha value: 0.5\n",
      "Best accuracy: 0.8056666666666666\n"
     ]
    }
   ],
   "source": [
    "def grid_search_alpha(vocabulary, sentiment_word_counts, num_fresh_documents, num_rotten_documents, dev_df, alphas):\n",
    "    best_alpha = None\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    for alpha in alphas:\n",
    "        # For each alpha calculating the conditional probability\n",
    "        fresh_probs_alpha, rotten_probs_alpha = calculate_conditional_probabilities(vocabulary, sentiment_word_counts, num_fresh_documents, num_rotten_documents, smoothing=alpha)\n",
    "        \n",
    "        # Count to store correct predictions\n",
    "        correct_predictions_alpha = 0\n",
    "        # Making prediction\n",
    "        for _, row in dev_df.iterrows():\n",
    "            sentiment, review = row['Freshness'], row['Review']\n",
    "            predicted_sentiment_alpha = naive_bayes_classifier(review, vocabulary, fresh_probs_alpha, rotten_probs_alpha)\n",
    "            if predicted_sentiment_alpha == sentiment:\n",
    "                correct_predictions_alpha += 1\n",
    "        # Calculating the accuracy\n",
    "        accuracy_alpha = correct_predictions_alpha / len(dev_df)\n",
    "        \n",
    "        # Updating beset alpha, based on the accuracy\n",
    "        if accuracy_alpha > best_accuracy:\n",
    "            best_alpha = alpha\n",
    "            best_accuracy = accuracy_alpha\n",
    "    \n",
    "    return best_alpha, best_accuracy\n",
    "\n",
    "# Defining different alpha values to experiment with\n",
    "alphas = [0, 0.1, 0.5, 1, 2, 5, 10]\n",
    "\n",
    "# Performing analysis\n",
    "best_alpha, best_accuracy = grid_search_alpha(vocabulary, sentiment_word_counts, num_fresh_documents, num_rotten_documents, dev_df, alphas)\n",
    "\n",
    "print(f\"Best alpha value: {best_alpha}\")\n",
    "print(f\"Best accuracy: {best_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words that predict 'fresh':\n",
      "['heartbreakingly', 'razor-sharp', 'beautifully.', 'flawless,', 'gem.', 'skilful', 'joyous,', 'cannily', 'rewarded.', 'petzold']\n",
      "\n",
      "Top 10 words that predict 'rotten':\n",
      "['charmless', 'unfunny', 'limp,', 'mirthless', 'lifeless.', 'flavorless', 'tediously', 'charmless,', 'yawn.', 'uninteresting,']\n"
     ]
    }
   ],
   "source": [
    "def calculate_class_given_word_probabilities(vocabulary, fresh_probs, rotten_probs, num_fresh_documents, num_rotten_documents):\n",
    "    fresh_given_word_probs = {}\n",
    "    rotten_given_word_probs = {}\n",
    "    \n",
    "    for word in vocabulary:\n",
    "        fresh_prob = fresh_probs[word]\n",
    "        rotten_prob = rotten_probs[word]\n",
    "        \n",
    "        prob_word = fresh_prob * num_fresh_documents + rotten_prob * num_rotten_documents\n",
    "        \n",
    "        fresh_given_word_prob = (fresh_prob * num_fresh_documents) / prob_word\n",
    "        rotten_given_word_prob = (rotten_prob * num_rotten_documents) / prob_word\n",
    "        \n",
    "        fresh_given_word_probs[word] = fresh_given_word_prob\n",
    "        rotten_given_word_probs[word] = rotten_given_word_prob\n",
    "    \n",
    "    return fresh_given_word_probs, rotten_given_word_probs\n",
    "\n",
    "# Calculating P[class | word] for each word\n",
    "fresh_given_word_probs, rotten_given_word_probs = calculate_class_given_word_probabilities(vocabulary, fresh_probs_smoothed, rotten_probs_smoothed, num_fresh_documents, num_rotten_documents)\n",
    "\n",
    "# Sorting the words by P[class | word] and get the top 10 words for each class\n",
    "top_fresh_words = sorted(fresh_given_word_probs, key=fresh_given_word_probs.get, reverse=True)[:10]\n",
    "top_rotten_words = sorted(rotten_given_word_probs, key=rotten_given_word_probs.get, reverse=True)[:10]\n",
    "\n",
    "print(\"Top 10 words that predict 'fresh':\")\n",
    "print(top_fresh_words)\n",
    "\n",
    "print(\"\\nTop 10 words that predict 'rotten':\")\n",
    "print(top_rotten_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy: 0.8032708333333334\n"
     ]
    }
   ],
   "source": [
    "# Calculating the conditional probabilities using the best alpha value\n",
    "fresh_probs_best_alpha, rotten_probs_best_alpha = calculate_conditional_probabilities(vocabulary, sentiment_word_counts, num_fresh_documents, num_rotten_documents, smoothing=best_alpha)\n",
    "\n",
    "# to store correct predictions\n",
    "correct_predictions_test = 0\n",
    "for _, row in test_df.iterrows():\n",
    "    sentiment, review = row['Freshness'], row['Review']\n",
    "    predicted_sentiment_test = naive_bayes_classifier(review, vocabulary, fresh_probs_best_alpha, rotten_probs_best_alpha)\n",
    "    if predicted_sentiment_test == sentiment:\n",
    "        correct_predictions_test += 1\n",
    "\n",
    "accuracy_test = correct_predictions_test / len(test_df)\n",
    "print(f\"Final accuracy: {accuracy_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
